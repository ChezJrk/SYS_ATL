{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations        # make Python behave\n",
    "import numpy as np                        # standard array library\n",
    "import time                               # timers\n",
    "import sys                                # add DSL library to the Python path\n",
    "sys.path.append(sys.path[0]+\"/..\")\n",
    "from SYS_ATL import proc                  # import the SYS-ATL DSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm going to define a 1-d version of a standard convolutional layer, like in CuDNN\n",
    "\n",
    "# K - # of output channels\n",
    "# C - # of input channels\n",
    "# W - length of the input signal/tensor\n",
    "# R - width of the filter kernel\n",
    "\n",
    "@proc\n",
    "def conv1d(K : size, C : size, W : size, R : size,\n",
    "           w : R[K,C,R],  # filter kernel weights\n",
    "           x : R[C,W],    # input signal\n",
    "           res : R[K,W],  # output signal\n",
    "):\n",
    "    # zero out the result memory\n",
    "    for k_init in par(0,K):\n",
    "        for i_init in par(0,W):\n",
    "            res[k_init, i_init] = 0.0\n",
    "    \n",
    "    # do the convolution\n",
    "    for k in par(0,K):\n",
    "        for c in par(0,C):\n",
    "            for i in par(0,W):\n",
    "                for r in par(0,R):\n",
    "                    if 0 <= i-r:\n",
    "                        res[k,i] += w[k,c,r] * x[c,i-r]\n",
    "\n",
    "conv1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One important early method of mapping Neural-Network Convolutions\n",
    "# onto high-performance Dense-Matrix-Multipliation primitives\n",
    "# was called `im2col` based on a related Matlab operation\n",
    "\n",
    "# Usually this transformation is explained with complex figures such as the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"im2col_explanation.png\">\n",
    "image from: https://leonardoaraujosantos.gitbook.io/artificial-\n",
    "inteligence/machine_learning/deep_learning/convolution_layer/making_faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let me show you a more straight-forwardly algebraic way\n",
    "# of understanding why im2col is an effective strategy\n",
    "# for computing convolutions\n",
    "\n",
    "# first, let's look at the inner statement of our convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "res[k, i] += w[k, c, r] * x[c, i - r]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If instead of `x[c, i-r]` we had `x[c, r, i]`\n",
    "# then treating `c,r` as a single variable,\n",
    "# this would look like the inner loop of a standard\n",
    "# dense-matrix-multiply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "res[k, i] += w[k, c,r] * x[c,r, i]\n",
    "\n",
    "# i.e. as matrices\n",
    "\n",
    "RES = W * X\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start applying scheduling\n",
    "im2col_conv = ( conv1d.rename('im2col_conv')\n",
    "                      .reorder('i','r')\n",
    "                      .bind_expr('y','x[c, i-r]')\n",
    "              )\n",
    "im2col_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice the `y : R` line which means\n",
    "# \"create a new buffer with type Real-Number\"\n",
    "# i.e. we are allocating a local scalar variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next, we can start to lift that allocation\n",
    "# up and out of the loop\n",
    "im2col_conv.lift_alloc('y:R', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im2col_conv = im2col_conv.lift_alloc('y:R', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, we can fission the loop correspondingly,\n",
    "# separating what is now a data-marshalling statement from\n",
    "# the actual compute statement in two subsequent\n",
    "# loop nests via fissioning\n",
    "im2col_conv.fission_after('y[c,r,i] = _',3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im2col_conv = im2col_conv.fission_after('y[c,r,i] = _',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im2col_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, in order to expose these two parts of the computation as\n",
    "# re-usable sub-procedures, we want a way to factor them out.\n",
    "im2col_conv, im2col = im2col_conv.factor_out_stmt('im2col', 'for c in _: _')\n",
    "im2col_conv, matmul = im2col_conv.factor_out_stmt('matmul', 'for k in _: _')\n",
    "im2col_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im2col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given this factoring, we can then proceed\n",
    "# to schedule these sub-procedures themselves.\n",
    "tiled_matmul =      (matmul.rename('tiled_matmul')\n",
    "                     # split the loops we want to tile together\n",
    "                     .reorder('r','i')\n",
    "                     .split('k',8,['khi','klo'], cut_tail=True)\n",
    "                     .reorder('klo[1]','c').reorder('klo[1]','i')\n",
    "                     .split('c[1]',8,['chi','clo'], cut_tail=True)\n",
    "                     .reorder('clo[1]','i').reorder('clo[1]','klo')\n",
    "                     .split('i[1]', 8, ['ihi','ilo'], cut_tail=True)\n",
    "                     .reorder('ilo[1]','klo').reorder('ilo[1]','clo'))\n",
    "tiled_matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# However, note that the convolution still calls the original matmul\n",
    "im2col_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can invoke another scheduling directive\n",
    "# to change which version of the matmul gets scheduled\n",
    "im2col_conv.call_eqv(tiled_matmul, 'matmul(_,_,_,_,_,_,_)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note!\n",
    "# Crucially this is only allowed because we know that\n",
    "#    matmul == tiled_matmul\n",
    "# by construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
