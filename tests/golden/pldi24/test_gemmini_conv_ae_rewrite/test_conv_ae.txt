
#include <stdint.h>
#include <stdbool.h>

// Compiler feature macros adapted from Hedley (public domain)
// https://github.com/nemequ/hedley

#if defined(__has_builtin)
#  define EXO_HAS_BUILTIN(builtin) __has_builtin(builtin)
#else
#  define EXO_HAS_BUILTIN(builtin) (0)
#endif

#if EXO_HAS_BUILTIN(__builtin_assume)
#  define EXO_ASSUME(expr) __builtin_assume(expr)
#elif EXO_HAS_BUILTIN(__builtin_unreachable)
#  define EXO_ASSUME(expr) \
      ((void)((expr) ? 1 : (__builtin_unreachable(), 1)))
#else
#  define EXO_ASSUME(expr) ((void)(expr))
#endif

typedef struct c_code_str_Context { 

    struct ConfigLoadAcc {
        bool stride_set;
    } ConfigLoadAcc;

    struct ConfigLoad_id1 {
        int_fast32_t src_stride;
    } ConfigLoad_id1;

    struct ConfigLoad_id2 {
        int_fast32_t src_stride;
    } ConfigLoad_id2;

    struct ConfigMatmul {
        bool done;
    } ConfigMatmul;

    struct ConfigStore {
        float scale;
        int_fast32_t dst_stride;
        bool act;
    } ConfigStore;

} c_code_str_Context;
#ifndef EXO_WIN_2I32
#define EXO_WIN_2I32
struct exo_win_2i32{
    int32_t * const data;
    const int_fast32_t strides[2];
};
#endif
#ifndef EXO_WIN_2I32C
#define EXO_WIN_2I32C
struct exo_win_2i32c{
    const int32_t * const data;
    const int_fast32_t strides[2];
};
#endif
#ifndef EXO_WIN_2I8
#define EXO_WIN_2I8
struct exo_win_2i8{
    int8_t * const data;
    const int_fast32_t strides[2];
};
#endif
#ifndef EXO_WIN_2I8C
#define EXO_WIN_2I8C
struct exo_win_2i8c{
    const int8_t * const data;
    const int_fast32_t strides[2];
};
#endif
#ifndef EXO_WIN_3I8
#define EXO_WIN_3I8
struct exo_win_3i8{
    int8_t * const data;
    const int_fast32_t strides[3];
};
#endif
// conv_on_gemmini(
//     output : i8[4, 56, 56, 64] @DRAM,
//     bias : i32[1, 64] @DRAM,
//     inp : i8[4, 58, 58, 64] @DRAM,
//     weights : i8[3, 3, 64, 64] @DRAM,
//     act : bool,
//     scale : f32 @DRAM
// )
void conv_on_gemmini( c_code_str_Context *ctxt, int8_t* output, const int32_t* bias, const int8_t* inp, const int8_t* weights, bool act, const float* scale );




#include <stdio.h>
#include <stdlib.h>

#include <include/gemmini.h>
#include "gemm_acc_malloc.h"
#include <include/gemmini.h>
#include "gemm_malloc.h"
double _relu_(double x) {
    if (x > 0.0) return x;
    else return 0.0;
}



/* relying on the following instruction..."
config_ld_acc_i32_vector(stride_set)
gemmini_extended3_config_ld(0, 1.0f, 0, 0);

*/

/* relying on the following instruction..."
config_ld_i8_id1(src_stride)
gemmini_extended3_config_ld({src_stride}, 1.0f, 0, 1);

*/

/* relying on the following instruction..."
config_ld_i8_id2(src_stride)
gemmini_extended3_config_ld({src_stride}, 1.0f, 0, 2);

*/

/* relying on the following instruction..."
config_matmul()
gemmini_extended_config_ex(WS, 0, 0, 0, 1, 0, 0);

*/

/* relying on the following instruction..."
config_st_acc_i8(scale,dst_stride,act)
gemmini_extended_config_st({dst_stride}, {act}, {scale}[0]);

*/
// conv_on_gemmini(
//     output : i8[4, 56, 56, 64] @DRAM,
//     bias : i32[1, 64] @DRAM,
//     inp : i8[4, 58, 58, 64] @DRAM,
//     weights : i8[3, 3, 64, 64] @DRAM,
//     act : bool,
//     scale : f32 @DRAM
// )
void conv_on_gemmini( c_code_str_Context *ctxt, int8_t* output, const int32_t* bias, const int8_t* inp, const int8_t* weights, bool act, const float* scale ) {
int8_t *inp_tmp = (int8_t*) ((uint64_t)gemm_malloc (16 * 8 * 4 * 3 * 30 * sizeof(int8_t)));
int8_t *weights_tmp = (int8_t*) ((uint64_t)gemm_malloc (16 * 16 * 4 * 4 * 3 * 3 * sizeof(int8_t)));
int32_t *res = (int32_t*) ((uint32_t)gemm_acc_malloc (16 * 8 * 4 * 2 * sizeof(int32_t)));
gemmini_extended_config_st((64), (act), (scale)[0]);

gemmini_extended_config_ex(WS, 0, 0, 0, 1, 0, 0);

gemmini_extended3_config_ld((64), 1.0f, 0, 2);

gemmini_extended3_config_ld((64), 1.0f, 0, 2);

gemmini_extended3_config_ld((64), 1.0f, 0, 1);

gemmini_extended3_config_ld(0, 1.0f, 0, 0);

int8_t *inp_tmp_1 = (int8_t*) ((uint64_t)gemm_malloc (16 * 16 * 4 * 3 * 30 * sizeof(int8_t)));
int8_t *weights_tmp_1 = (int8_t*) ((uint64_t)gemm_malloc (16 * 16 * 4 * 4 * 3 * 3 * sizeof(int8_t)));
for (int_fast32_t b = 0; b < 4; b++) {
  for (int_fast32_t ocolo = 0; ocolo < 3; ocolo++) {
    int32_t *res_1 = (int32_t*) ((uint32_t)gemm_acc_malloc (16 * 16 * 4 * sizeof(int32_t)));
    for (int_fast32_t orowo = 0; orowo < 2; orowo++) {
      for (int_fast32_t orowi = 0; orowi < 28; orowi++) {
        for (int_fast32_t ocho = 0; ocho < 4; ocho++) {
          gemmini_extended_mvin( ((uint64_t) &bias[16 * ocho]), ((uint32_t) &*(int32_t*)((uint64_t)( ((uint32_t)((uint64_t)res_1)) + ((ocho) * (256))/16))), 16, (16) );
        }
        for (int_fast32_t krow = 0; krow < 3; krow++) {
          for (int_fast32_t kcol = 0; kcol < 3; kcol++) {
            for (int_fast32_t kcho = 0; kcho < 4; kcho++) {
              if (orowo == 0) {
                if (orowi == 0) {
                  gemmini_extended_mvin2( &weights[(krow) * (12288) + (kcol) * (4096) + (16 * kcho) * (64)], ((uint64_t) &*(int8_t*)((uint64_t)( ((uint32_t)((uint64_t)weights_tmp_1)) + ((krow) * (12288) + (kcol) * (4096) + (kcho) * (1024))/16))), 16*(4), (16) );
                }
              }
            }
            if (orowi == 0 || krow == 2) {
              gemmini_extended_mvin3( &inp[(b) * (215296) + (krow + orowi + 28 * orowo) * (3712) + (kcol + 16 * ocolo) * (64)], ((uint64_t) &*(int8_t*)((uint64_t)( ((uint32_t)((uint64_t)inp_tmp_1)) + ((krow + orowi) * (3072) + (kcol) * (1024))/16))), 16*(4), (16) );
            }
            for (int_fast32_t ocho = 0; ocho < 4; ocho++) {
              for (int_fast32_t kcho = 0; kcho < 4; kcho++) {
                gemmini_extended_preload((uint32_t)(&*(int8_t*)((uint64_t)( ((uint32_t)((uint64_t)weights_tmp_1)) + ((krow) * (12288) + (kcol) * (4096) + (kcho) * (1024) + (ocho) * (256))/16))), (uint32_t)(&*(int32_t*)((uint64_t)( ((uint32_t)((uint64_t)res_1)) + ((ocho) * (256))/16))) | 0x40000000, (16), (16), (16), (16));
gemmini_extended_compute_preloaded((uint32_t)(&*(int8_t*)((uint64_t)( ((uint32_t)((uint64_t)inp_tmp_1)) + ((krow + orowi) * (3072) + (kcol) * (1024) + (kcho) * (256))/16))), ~((uint32_t)0), (16), (16), 16, 16);
              }
            }
          }
        }
        for (int_fast32_t ocho = 0; ocho < 4; ocho++) {
          gemmini_extended_mvout( ((uint64_t) &output[(b) * (200704) + (orowi + 28 * orowo) * (3584) + (16 * ocolo) * (64) + 16 * ocho]), (uint32_t) &*(int32_t*)((uint64_t)( ((uint32_t)((uint64_t)res_1)) + ((ocho) * (256))/16)), (16), (16) );
        }
      }
    }
    gemm_acc_free((uint32_t)(res_1));
  }
  for (int_fast32_t orowo = 0; orowo < 2; orowo++) {
    for (int_fast32_t orowi = 0; orowi < 28; orowi++) {
      for (int_fast32_t ocho = 0; ocho < 4; ocho++) {
        gemmini_extended_mvin( ((uint64_t) &bias[16 * ocho]), ((uint32_t) &*(int32_t*)((uint64_t)( ((uint32_t)((uint64_t)res)) + ((orowo) * (512) + (ocho) * (128))/16))), 16, (8) );
      }
      for (int_fast32_t krow = 0; krow < 3; krow++) {
        for (int_fast32_t kcol = 0; kcol < 3; kcol++) {
          for (int_fast32_t kcho = 0; kcho < 4; kcho++) {
            if (orowo == 0) {
              if (orowi == 0) {
                gemmini_extended_mvin2( &weights[(krow) * (12288) + (kcol) * (4096) + (16 * kcho) * (64)], ((uint64_t) &*(int8_t*)((uint64_t)( ((uint32_t)((uint64_t)weights_tmp)) + ((krow) * (12288) + (kcol) * (4096) + (kcho) * (1024))/16))), 16*(4), (16) );
              }
            }
          }
          if (orowi == 0 || krow == 2) {
            gemmini_extended_mvin3( &inp[(b) * (215296) + (krow + orowi + 28 * orowo) * (3712) + (48 + kcol) * (64)], ((uint64_t) &*(int8_t*)((uint64_t)( ((uint32_t)((uint64_t)inp_tmp)) + ((krow + orowi) * (1536) + (kcol) * (512))/16))), 16*(4), (8) );
          }
          for (int_fast32_t ocho = 0; ocho < 4; ocho++) {
            for (int_fast32_t kcho = 0; kcho < 4; kcho++) {
              gemmini_extended_preload((uint32_t)(&*(int8_t*)((uint64_t)( ((uint32_t)((uint64_t)weights_tmp)) + ((krow) * (12288) + (kcol) * (4096) + (kcho) * (1024) + (ocho) * (256))/16))), (uint32_t)(&*(int32_t*)((uint64_t)( ((uint32_t)((uint64_t)res)) + ((orowo) * (512) + (ocho) * (128))/16))) | 0x40000000, (16), (16), (16), (8));
gemmini_extended_compute_preloaded((uint32_t)(&*(int8_t*)((uint64_t)( ((uint32_t)((uint64_t)inp_tmp)) + ((krow + orowi) * (1536) + (kcol) * (512) + (kcho) * (128))/16))), ~((uint32_t)0), (16), (8), 16, 16);
            }
          }
        }
      }
      for (int_fast32_t ocho = 0; ocho < 4; ocho++) {
        gemmini_extended_mvout( ((uint64_t) &output[(b) * (200704) + (orowi + 28 * orowo) * (3584) + (48) * (64) + 16 * ocho]), (uint32_t) &*(int32_t*)((uint64_t)( ((uint32_t)((uint64_t)res)) + ((orowo) * (512) + (ocho) * (128))/16)), (16), (8) );
      }
    }
  }
}
gemm_free((uint64_t)(weights_tmp_1));
gemm_free((uint64_t)(inp_tmp_1));
gemm_acc_free((uint32_t)(res));
gemm_free((uint64_t)(weights_tmp));
gemm_free((uint64_t)(inp_tmp));
}


/* relying on the following instruction..."
do_ld_acc_i32_vector(n,src,dst)
gemmini_extended_mvin( ((uint64_t) &{src_data}), ((uint32_t) &{dst_data}), 16, {n} );
*/

/* relying on the following instruction..."
do_ld_i8_block_id1(n,m,src,dst)
gemmini_extended_mvin2( &{src_data}, ((uint64_t) &{dst_data}), 16*{m}, {n} );
*/

/* relying on the following instruction..."
do_ld_i8_block_id2(n,m,src,dst)
gemmini_extended_mvin3( &{src_data}, ((uint64_t) &{dst_data}), 16*{m}, {n} );
*/

/* relying on the following instruction..."
do_matmul_acc_i8(N,M,K,A,B,C)
gemmini_extended_preload((uint32_t)(&{B_data}), (uint32_t)(&{C_data}) | 0x40000000, {M}, {K}, {M}, {N});
gemmini_extended_compute_preloaded((uint32_t)(&{A_data}), ~((uint32_t)0), {K}, {N}, 16, 16);
*/

/* relying on the following instruction..."
do_st_acc_i8(n,m,src,dst)
gemmini_extended_mvout( ((uint64_t) &{dst_data}), (uint32_t) &{src_data}, {m}, {n} );
*/
